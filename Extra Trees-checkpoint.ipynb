{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n",
      "Clearing...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'the label [0] is not in the [columns]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1324\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1325\u001b[1;33m                     \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1326\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36merror\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1319\u001b[0m                 raise KeyError(\"the label [%s] is not in the [%s]\" %\n\u001b[1;32m-> 1320\u001b[1;33m                                (key, self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'the label [0] is not in the [columns]'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6b53e82cb1c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcolnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \"\"\"            \n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1224\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1225\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1226\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1227\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    736\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 738\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    861\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_label_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m                 \u001b[0msection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m                 \u001b[1;31m# we have yielded a scalar ?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1371\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1372\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1331\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1333\u001b[1;33m                 \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36merror\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1318\u001b[0m                         \"cannot use label indexing with a null key\")\n\u001b[0;32m   1319\u001b[0m                 raise KeyError(\"the label [%s] is not in the [%s]\" %\n\u001b[1;32m-> 1320\u001b[1;33m                                (key, self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'the label [0] is not in the [columns]'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import ensemble\n",
    "\n",
    "\n",
    "print('Load data...')\n",
    "train = pd.read_csv(\"C://users//Robert//Downloads//train.csv\")\n",
    "target = train['target'].values\n",
    "train = train.drop(['ID','target','v8','v23','v25','v31','v36','v37','v46','v51','v53','v54','v63','v73','v75','v79','v81','v82','v89','v92','v95','v105','v107','v108','v109','v110','v116','v117','v118','v119','v123','v124','v128'],axis=1)\n",
    "test = pd.read_csv(\"C://users//Robert//Downloads//test.csv\")\n",
    "id_test = test['ID'].values\n",
    "test = test.drop(['ID','v8','v23','v25','v31','v36','v37','v46','v51','v53','v54','v63','v73','v75','v79','v81','v82','v89','v92','v95','v105','v107','v108','v109','v110','v116','v117','v118','v119','v123','v124','v128'],axis=1)\n",
    "train['pop']=train.shape[1]-train.count(axis=1, level=None, numeric_only=False)\n",
    "test['pop']=test.shape[1]-test.count(axis=1, level=None, numeric_only=False)\n",
    "colnames=list(train.columns.values)\n",
    "for value in colnames:\n",
    "    newcol=value+\"p\"\n",
    "    train[newcol]=train[value].isnull().astype(int)\n",
    "    test[newcol]=test[value].isnull().astype(int)\n",
    "print('Clearing...')\n",
    "for f in train_df.columns:\n",
    "    if train_df[f].dtype == 'object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(np.unique(list(train_df[f].values)  + list(test_df[f].values)))\n",
    "        train_df[f]   = lbl.transform(list(train_df[f].values))\n",
    "        test_df[f]  = lbl.transform(list(test_df[f].values))\n",
    "colnames=list(train.columns.values)\n",
    "colnames=colnames[0:100]\n",
    "start=0\n",
    "stop=20\n",
    "mid=start\n",
    "\n",
    "l=len(colnames)\n",
    "for i in range(start,stop):\n",
    "    for j in range(mid,stop):\n",
    "        label=colnames[i]+\"x\"+colnames[j]\n",
    "        train[label]=train.iloc[:,i]*train.iloc[:,j]\n",
    "        test[label]=test.iloc[:,i]*test.iloc[:,j]\n",
    "    mid=mid+1\n",
    "start=0\n",
    "stop=20\n",
    "mid=start\n",
    "\n",
    "l=len(colnames)\n",
    "for i in range(start,stop):\n",
    "    for j in range(mid,stop):\n",
    "        label=colnames[i]+\"x\"+colnames[j]\n",
    "        train[label]=train.iloc[:,i]*train.iloc[:,j]\n",
    "        test[label]=test.iloc[:,i]*test.iloc[:,j]\n",
    "    mid=mid+1\n",
    "start=0\n",
    "stop=20\n",
    "mid=start\n",
    "\n",
    "l=len(colnames)\n",
    "for i in range(start,stop):\n",
    "    for j in range(mid,stop):\n",
    "        label=colnames[i]+\"x\"+colnames[j]\n",
    "        train[label]=train.iloc[:,i]*train.iloc[:,j]\n",
    "        test[label]=test.iloc[:,i]*test.iloc[:,j]\n",
    "    mid=mid+1\n",
    "start=0\n",
    "stop=20\n",
    "mid=start\n",
    "\n",
    "l=len(colnames)\n",
    "for i in range(start,stop):\n",
    "    for j in range(mid,stop):\n",
    "        label=colnames[i]+\"x\"+colnames[j]\n",
    "        train[label]=train.iloc[:,i]*train.iloc[:,j]\n",
    "        test[label]=test.iloc[:,i]*test.iloc[:,j]\n",
    "    mid=mid+1\n",
    "start=0\n",
    "stop=20\n",
    "mid=start\n",
    "\n",
    "l=len(colnames)\n",
    "for i in range(start,stop):\n",
    "    for j in range(mid,stop):\n",
    "        label=colnames[i]+\"x\"+colnames[j]\n",
    "        train[label]=train.iloc[:,i]*train.iloc[:,j]\n",
    "        test[label]=test.iloc[:,i]*test.iloc[:,j]\n",
    "    mid=mid+1\n",
    "train.fillna(-999)\n",
    "test.fillna(-999)\n",
    "\"\"\"            \n",
    "\n",
    "\"\"\"\n",
    "X_train = train\n",
    "X_test = test\n",
    "print('Training...')\n",
    "extc = ExtraTreesClassifier(n_estimators=850,max_features= 40,criterion= 'entropy',min_samples_split= 4,\n",
    "                            max_depth= 30, min_samples_leaf= 2, n_jobs = -1)      \n",
    "\n",
    "extc.fit(X_train,target) \n",
    "\n",
    "print('Predict...')\n",
    "y_pred = extc.predict_proba(X_test)\n",
    "#print y_pred\n",
    "\n",
    "pd.DataFrame({\"ID\": id_test, \"PredictedProb\": y_pred[:,1]}).to_csv('extra_trees2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature v50 (0.077699) (float64)\n",
      "2. feature v66 (0.034776) (int32)\n",
      "3. feature v10 (0.028896) (float64)\n",
      "4. feature v12 (0.027635) (float64)\n",
      "5. feature v114 (0.026032) (float64)\n",
      "6. feature v52 (0.025462) (int32)\n",
      "7. feature v40 (0.025396) (float64)\n",
      "8. feature v56 (0.024458) (int32)\n",
      "9. feature v91 (0.024364) (int32)\n",
      "10. feature v14 (0.023987) (float64)\n",
      "11. feature v34 (0.023335) (float64)\n",
      "12. feature v125 (0.023160) (int32)\n",
      "13. feature v22 (0.022790) (int32)\n",
      "14. feature v112 (0.022780) (int32)\n",
      "15. feature v24 (0.022200) (int32)\n",
      "16. feature v21 (0.020292) (float64)\n",
      "17. feature v62 (0.019834) (int64)\n",
      "18. feature v47 (0.019217) (int32)\n",
      "19. feature v113p (0.018598) (int32)\n",
      "20. feature v71 (0.017513) (int32)\n",
      "21. feature v129 (0.015548) (int64)\n",
      "22. feature v113 (0.015445) (int32)\n",
      "23. feature v72 (0.013784) (int64)\n",
      "24. feature v30 (0.011552) (int32)\n",
      "25. feature v30p (0.009265) (int32)\n",
      "26. feature pop (0.007212) (int64)\n",
      "27. feature v87 (0.007070) (float64)\n",
      "28. feature v5 (0.007041) (float64)\n",
      "29. feature v98 (0.006945) (float64)\n",
      "30. feature v70 (0.006801) (float64)\n",
      "31. feature v100 (0.005696) (float64)\n",
      "32. feature v28 (0.005678) (float64)\n",
      "33. feature v120 (0.005673) (float64)\n",
      "34. feature v58 (0.005657) (float64)\n",
      "35. feature v1 (0.005649) (float64)\n",
      "36. feature v6 (0.005563) (float64)\n",
      "37. feature v99 (0.005490) (float64)\n",
      "38. feature v131 (0.005475) (float64)\n",
      "39. feature v2 (0.005458) (float64)\n",
      "40. feature v69 (0.005404) (float64)\n",
      "41. feature v45 (0.005369) (float64)\n",
      "42. feature v88 (0.005361) (float64)\n",
      "43. feature v115 (0.005360) (float64)\n",
      "44. feature v57 (0.005356) (float64)\n",
      "45. feature v78 (0.005343) (float64)\n",
      "46. feature v16 (0.005332) (float64)\n",
      "47. feature v9 (0.005268) (float64)\n",
      "48. feature v122 (0.005252) (float64)\n",
      "49. feature v97 (0.005203) (float64)\n",
      "50. feature v18 (0.005195) (float64)\n",
      "51. feature v127 (0.005193) (float64)\n",
      "52. feature v80 (0.005183) (float64)\n",
      "53. feature v44 (0.005171) (float64)\n",
      "54. feature v35 (0.005135) (float64)\n",
      "55. feature v26 (0.005107) (float64)\n",
      "56. feature v59 (0.005104) (float64)\n",
      "57. feature v7 (0.005093) (float64)\n",
      "58. feature v90 (0.005078) (float64)\n",
      "59. feature v11 (0.005073) (float64)\n",
      "60. feature v85 (0.005053) (float64)\n",
      "61. feature v43 (0.005051) (float64)\n",
      "62. feature v101 (0.005050) (float64)\n",
      "63. feature v103 (0.005046) (float64)\n",
      "64. feature v60 (0.005033) (float64)\n",
      "65. feature v4 (0.005014) (float64)\n",
      "66. feature v27 (0.005013) (float64)\n",
      "67. feature v68 (0.005000) (float64)\n",
      "68. feature v102 (0.004964) (float64)\n",
      "69. feature v86 (0.004958) (float64)\n",
      "70. feature v42 (0.004948) (float64)\n",
      "71. feature v126 (0.004925) (float64)\n",
      "72. feature v15 (0.004915) (float64)\n",
      "73. feature v84 (0.004909) (float64)\n",
      "74. feature v111 (0.004864) (float64)\n",
      "75. feature v32 (0.004862) (float64)\n",
      "76. feature v61 (0.004853) (float64)\n",
      "77. feature v55 (0.004790) (float64)\n",
      "78. feature v20 (0.004785) (float64)\n",
      "79. feature v94 (0.004780) (float64)\n",
      "80. feature v49 (0.004740) (float64)\n",
      "81. feature v77 (0.004731) (float64)\n",
      "82. feature v56p (0.004720) (int32)\n",
      "83. feature v38 (0.004696) (int64)\n",
      "84. feature v83 (0.004658) (float64)\n",
      "85. feature v121 (0.004650) (float64)\n",
      "86. feature v104 (0.004645) (float64)\n",
      "87. feature v13 (0.004614) (float64)\n",
      "88. feature v67 (0.004605) (float64)\n",
      "89. feature v106 (0.004603) (float64)\n",
      "90. feature v41 (0.004594) (float64)\n",
      "91. feature v33 (0.004588) (float64)\n",
      "92. feature v39 (0.004571) (float64)\n",
      "93. feature v48 (0.004546) (float64)\n",
      "94. feature v65 (0.004534) (float64)\n",
      "95. feature v19 (0.004510) (float64)\n",
      "96. feature v93 (0.004502) (float64)\n",
      "97. feature v96 (0.004501) (float64)\n",
      "98. feature v130 (0.004485) (float64)\n",
      "99. feature v29 (0.004484) (float64)\n",
      "100. feature v64 (0.004456) (float64)\n",
      "101. feature v17 (0.004421) (float64)\n",
      "102. feature v76 (0.004377) (float64)\n",
      "103. feature v3p (0.001531) (int32)\n",
      "104. feature v3 (0.001246) (int32)\n",
      "105. feature v74 (0.001244) (int32)\n",
      "106. feature v102p (0.000737) (int32)\n",
      "107. feature v22p (0.000560) (int32)\n",
      "108. feature v5p (0.000498) (int32)\n",
      "109. feature v112p (0.000469) (int32)\n",
      "110. feature v98p (0.000461) (int32)\n",
      "111. feature v87p (0.000446) (int32)\n",
      "112. feature v70p (0.000435) (int32)\n",
      "113. feature v21p (0.000368) (int32)\n",
      "114. feature v85p (0.000167) (int32)\n",
      "115. feature v69p (0.000104) (int32)\n",
      "116. feature v131p (0.000101) (int32)\n",
      "117. feature v16p (0.000097) (int32)\n",
      "118. feature v78p (0.000093) (int32)\n",
      "119. feature v115p (0.000091) (int32)\n",
      "120. feature v125p (0.000065) (int32)\n",
      "121. feature v9p (0.000061) (int32)\n",
      "122. feature v4p (0.000057) (int32)\n",
      "123. feature v122p (0.000056) (int32)\n",
      "124. feature v2p (0.000056) (int32)\n",
      "125. feature v44p (0.000056) (int32)\n",
      "126. feature v48p (0.000055) (int32)\n",
      "127. feature v80p (0.000055) (int32)\n",
      "128. feature v17p (0.000055) (int32)\n",
      "129. feature v61p (0.000054) (int32)\n",
      "130. feature v64p (0.000054) (int32)\n",
      "131. feature v76p (0.000054) (int32)\n",
      "132. feature v101p (0.000052) (int32)\n",
      "133. feature v19p (0.000052) (int32)\n",
      "134. feature v67p (0.000051) (int32)\n",
      "135. feature v106p (0.000051) (int32)\n",
      "136. feature v43p (0.000050) (int32)\n",
      "137. feature v59p (0.000050) (int32)\n",
      "138. feature v130p (0.000050) (int32)\n",
      "139. feature v55p (0.000049) (int32)\n",
      "140. feature v121p (0.000049) (int32)\n",
      "141. feature v97p (0.000049) (int32)\n",
      "142. feature v90p (0.000049) (int32)\n",
      "143. feature v41p (0.000048) (int32)\n",
      "144. feature v7p (0.000048) (int32)\n",
      "145. feature v99p (0.000048) (int32)\n",
      "146. feature v11p (0.000048) (int32)\n",
      "147. feature v77p (0.000048) (int32)\n",
      "148. feature v127p (0.000048) (int32)\n",
      "149. feature v68p (0.000047) (int32)\n",
      "150. feature v45p (0.000047) (int32)\n",
      "151. feature v60p (0.000047) (int32)\n",
      "152. feature v57p (0.000047) (int32)\n",
      "153. feature v29p (0.000046) (int32)\n",
      "154. feature v93p (0.000046) (int32)\n",
      "155. feature v84p (0.000046) (int32)\n",
      "156. feature v104p (0.000046) (int32)\n",
      "157. feature v35p (0.000046) (int32)\n",
      "158. feature v26p (0.000046) (int32)\n",
      "159. feature v83p (0.000046) (int32)\n",
      "160. feature v49p (0.000046) (int32)\n",
      "161. feature v28p (0.000046) (int32)\n",
      "162. feature v120p (0.000046) (int32)\n",
      "163. feature v65p (0.000046) (int32)\n",
      "164. feature v13p (0.000045) (int32)\n",
      "165. feature v20p (0.000045) (int32)\n",
      "166. feature v27p (0.000045) (int32)\n",
      "167. feature v86p (0.000045) (int32)\n",
      "168. feature v88p (0.000045) (int32)\n",
      "169. feature v1p (0.000045) (int32)\n",
      "170. feature v94p (0.000045) (int32)\n",
      "171. feature v100p (0.000045) (int32)\n",
      "172. feature v6p (0.000045) (int32)\n",
      "173. feature v96p (0.000045) (int32)\n",
      "174. feature v18p (0.000045) (int32)\n",
      "175. feature v42p (0.000045) (int32)\n",
      "176. feature v15p (0.000045) (int32)\n",
      "177. feature v111p (0.000044) (int32)\n",
      "178. feature v32p (0.000044) (int32)\n",
      "179. feature v50p (0.000044) (int32)\n",
      "180. feature v58p (0.000043) (int32)\n",
      "181. feature v103p (0.000043) (int32)\n",
      "182. feature v33p (0.000043) (int32)\n",
      "183. feature v39p (0.000042) (int32)\n",
      "184. feature v126p (0.000041) (int32)\n",
      "185. feature v12p (0.000037) (int32)\n",
      "186. feature v40p (0.000036) (int32)\n",
      "187. feature v10p (0.000035) (int32)\n",
      "188. feature v34p (0.000034) (int32)\n",
      "189. feature v114p (0.000018) (int32)\n",
      "190. feature v14p (0.000000) (int32)\n",
      "191. feature v52p (0.000000) (int32)\n",
      "192. feature v91p (0.000000) (int32)\n",
      "193. feature v62p (0.000000) (int32)\n",
      "194. feature v66p (0.000000) (int32)\n",
      "195. feature v47p (0.000000) (int32)\n",
      "196. feature v129p (0.000000) (int32)\n",
      "197. feature v38p (0.000000) (int32)\n",
      "198. feature v71p (0.000000) (int32)\n",
      "199. feature v72p (0.000000) (int32)\n",
      "200. feature v24p (0.000000) (int32)\n",
      "201. feature v74p (0.000000) (int32)\n",
      "202. feature popp (0.000000) (int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "X=X_train\n",
    "y=target\n",
    "extc.fit(X, y)\n",
    "importances = extc.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in extc.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "cols=list(train.columns.values)\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %s (%f) (%s)\" % (f + 1, cols[indices[f]], importances[indices[f]], X.iloc[:,indices[f]].dtype))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n",
      "Clearing...\n",
      "v1xv1\n",
      "v1xv2\n",
      "v1xv3\n",
      "v1xv4\n",
      "v1xv5\n",
      "v1xv6\n",
      "v1xv7\n",
      "v1xv9\n",
      "v1xv10\n",
      "v1xv11\n",
      "v1xv12\n",
      "v1xv13\n",
      "v1xv14\n",
      "v1xv15\n",
      "v1xv16\n",
      "v1xv17\n",
      "v1xv18\n",
      "v1xv19\n",
      "v1xv20\n",
      "v1xv21\n",
      "v2xv2\n",
      "v2xv3\n",
      "v2xv4\n",
      "v2xv5\n",
      "v2xv6\n",
      "v2xv7\n",
      "v2xv9\n",
      "v2xv10\n",
      "v2xv11\n",
      "v2xv12\n",
      "v2xv13\n",
      "v2xv14\n",
      "v2xv15\n",
      "v2xv16\n",
      "v2xv17\n",
      "v2xv18\n",
      "v2xv19\n",
      "v2xv20\n",
      "v2xv21\n",
      "v3xv3\n",
      "v3xv4\n",
      "v3xv5\n",
      "v3xv6\n",
      "v3xv7\n",
      "v3xv9\n",
      "v3xv10\n",
      "v3xv11\n",
      "v3xv12\n",
      "v3xv13\n",
      "v3xv14\n",
      "v3xv15\n",
      "v3xv16\n",
      "v3xv17\n",
      "v3xv18\n",
      "v3xv19\n",
      "v3xv20\n",
      "v3xv21\n",
      "v4xv4\n",
      "v4xv5\n",
      "v4xv6\n",
      "v4xv7\n",
      "v4xv9\n",
      "v4xv10\n",
      "v4xv11\n",
      "v4xv12\n",
      "v4xv13\n",
      "v4xv14\n",
      "v4xv15\n",
      "v4xv16\n",
      "v4xv17\n",
      "v4xv18\n",
      "v4xv19\n",
      "v4xv20\n",
      "v4xv21\n",
      "v5xv5\n",
      "v5xv6\n",
      "v5xv7\n",
      "v5xv9\n",
      "v5xv10\n",
      "v5xv11\n",
      "v5xv12\n",
      "v5xv13\n",
      "v5xv14\n",
      "v5xv15\n",
      "v5xv16\n",
      "v5xv17\n",
      "v5xv18\n",
      "v5xv19\n",
      "v5xv20\n",
      "v5xv21\n",
      "v6xv6\n",
      "v6xv7\n",
      "v6xv9\n",
      "v6xv10\n",
      "v6xv11\n",
      "v6xv12\n",
      "v6xv13\n",
      "v6xv14\n",
      "v6xv15\n",
      "v6xv16\n",
      "v6xv17\n",
      "v6xv18\n",
      "v6xv19\n",
      "v6xv20\n",
      "v6xv21\n",
      "v7xv7\n",
      "v7xv9\n",
      "v7xv10\n",
      "v7xv11\n",
      "v7xv12\n",
      "v7xv13\n",
      "v7xv14\n",
      "v7xv15\n",
      "v7xv16\n",
      "v7xv17\n",
      "v7xv18\n",
      "v7xv19\n",
      "v7xv20\n",
      "v7xv21\n",
      "v9xv9\n",
      "v9xv10\n",
      "v9xv11\n",
      "v9xv12\n",
      "v9xv13\n",
      "v9xv14\n",
      "v9xv15\n",
      "v9xv16\n",
      "v9xv17\n",
      "v9xv18\n",
      "v9xv19\n",
      "v9xv20\n",
      "v9xv21\n",
      "v10xv10\n",
      "v10xv11\n",
      "v10xv12\n",
      "v10xv13\n",
      "v10xv14\n",
      "v10xv15\n",
      "v10xv16\n",
      "v10xv17\n",
      "v10xv18\n",
      "v10xv19\n",
      "v10xv20\n",
      "v10xv21\n",
      "v11xv11\n",
      "v11xv12\n",
      "v11xv13\n",
      "v11xv14\n",
      "v11xv15\n",
      "v11xv16\n",
      "v11xv17\n",
      "v11xv18\n",
      "v11xv19\n",
      "v11xv20\n",
      "v11xv21\n",
      "v12xv12\n",
      "v12xv13\n",
      "v12xv14\n",
      "v12xv15\n",
      "v12xv16\n",
      "v12xv17\n",
      "v12xv18\n",
      "v12xv19\n",
      "v12xv20\n",
      "v12xv21\n",
      "v13xv13\n",
      "v13xv14\n",
      "v13xv15\n",
      "v13xv16\n",
      "v13xv17\n",
      "v13xv18\n",
      "v13xv19\n",
      "v13xv20\n",
      "v13xv21\n",
      "v14xv14\n",
      "v14xv15\n",
      "v14xv16\n",
      "v14xv17\n",
      "v14xv18\n",
      "v14xv19\n",
      "v14xv20\n",
      "v14xv21\n",
      "v15xv15\n",
      "v15xv16\n",
      "v15xv17\n",
      "v15xv18\n",
      "v15xv19\n",
      "v15xv20\n",
      "v15xv21\n",
      "v16xv16\n",
      "v16xv17\n",
      "v16xv18\n",
      "v16xv19\n",
      "v16xv20\n",
      "v16xv21\n",
      "v17xv17\n",
      "v17xv18\n",
      "v17xv19\n",
      "v17xv20\n",
      "v17xv21\n",
      "v18xv18\n",
      "v18xv19\n",
      "v18xv20\n",
      "v18xv21\n",
      "v19xv19\n",
      "v19xv20\n",
      "v19xv21\n",
      "v20xv20\n",
      "v20xv21\n",
      "v21xv21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import ensemble\n",
    "\n",
    "\n",
    "print('Load data...')\n",
    "train = pd.read_csv(\"C://users//Robert//Downloads//train.csv\")\n",
    "target = train['target'].values\n",
    "train = train.drop(['ID','target','v8','v23','v25','v31','v36','v37','v46','v51','v53','v54','v63','v73','v75','v79','v81','v82','v89','v92','v95','v105','v107','v108','v109','v110','v116','v117','v118','v119','v123','v124','v128'],axis=1)\n",
    "test = pd.read_csv(\"C://users//Robert//Downloads//test.csv\")\n",
    "id_test = test['ID'].values\n",
    "test = test.drop(['ID','v8','v23','v25','v31','v36','v37','v46','v51','v53','v54','v63','v73','v75','v79','v81','v82','v89','v92','v95','v105','v107','v108','v109','v110','v116','v117','v118','v119','v123','v124','v128'],axis=1)\n",
    "train['pop']=train.shape[1]-train.count(axis=1, level=None, numeric_only=False)\n",
    "test['pop']=test.shape[1]-test.count(axis=1, level=None, numeric_only=False)\n",
    "colnames=list(train.columns.values)\n",
    "for value in colnames:\n",
    "    newcol=value+\"p\"\n",
    "    train[newcol]=train[value].isnull().astype(int)\n",
    "    test[newcol]=test[value].isnull().astype(int)\n",
    "print('Clearing...')\n",
    "for (train_name, train_series), (test_name, test_series) in zip(train.iteritems(),test.iteritems()):\n",
    "    if train_series.dtype == 'O':\n",
    "        #for objects: factorize\n",
    "        train[train_name], tmp_indexer = pd.factorize(train[train_name])\n",
    "        test[test_name] = tmp_indexer.get_indexer(test[test_name])\n",
    "        #but now we have -1 values (NaN)\n",
    "    else:\n",
    "        #for int or float: fill NaN\n",
    "        tmp_len = len(train[train_series.isnull()])\n",
    "        if tmp_len>0:\n",
    "            #print \"mean\", train_series.mean()\n",
    "            train.loc[train_series.isnull(), train_name] = -999 \n",
    "        #and Test\n",
    "        tmp_len = len(test[test_series.isnull()])\n",
    "        if tmp_len>0:\n",
    "            test.loc[test_series.isnull(), test_name] = -999\n",
    "colnames=list(train.columns.values)\n",
    "colnames=colnames[0:100]\n",
    "start=0\n",
    "mid=start\n",
    "stop=20\n",
    "len(colnames)\n",
    "a=0\n",
    "l=len(colnames)\n",
    "for i in range(start,stop):\n",
    "    for j in range(mid,stop):\n",
    "        label=colnames[i]+\"x\"+colnames[j]\n",
    "        print(label)\n",
    "        train[label]=train.iloc[:,i]*train.iloc[:,j]\n",
    "    mid=mid+1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v100xv100\n",
      "v100xv101\n",
      "v100xv102\n",
      "v100xv103\n",
      "v100xv104\n",
      "v100xv106\n",
      "v100xv111\n",
      "v100xv112\n",
      "v100xv113\n",
      "v100xv114\n",
      "v100xv115\n",
      "v100xv120\n",
      "v100xv121\n",
      "v100xv122\n",
      "v100xv125\n",
      "v100xv126\n",
      "v100xv127\n",
      "v100xv129\n",
      "v100xv130\n",
      "v100xv131\n",
      "v101xv101\n",
      "v101xv102\n",
      "v101xv103\n",
      "v101xv104\n",
      "v101xv106\n",
      "v101xv111\n",
      "v101xv112\n",
      "v101xv113\n",
      "v101xv114\n",
      "v101xv115\n",
      "v101xv120\n",
      "v101xv121\n",
      "v101xv122\n",
      "v101xv125\n",
      "v101xv126\n",
      "v101xv127\n",
      "v101xv129\n",
      "v101xv130\n",
      "v101xv131\n",
      "v102xv102\n",
      "v102xv103\n",
      "v102xv104\n",
      "v102xv106\n",
      "v102xv111\n",
      "v102xv112\n",
      "v102xv113\n",
      "v102xv114\n",
      "v102xv115\n",
      "v102xv120\n",
      "v102xv121\n",
      "v102xv122\n",
      "v102xv125\n",
      "v102xv126\n",
      "v102xv127\n",
      "v102xv129\n",
      "v102xv130\n",
      "v102xv131\n",
      "v103xv103\n",
      "v103xv104\n",
      "v103xv106\n",
      "v103xv111\n",
      "v103xv112\n",
      "v103xv113\n",
      "v103xv114\n",
      "v103xv115\n",
      "v103xv120\n",
      "v103xv121\n",
      "v103xv122\n",
      "v103xv125\n",
      "v103xv126\n",
      "v103xv127\n",
      "v103xv129\n",
      "v103xv130\n",
      "v103xv131\n",
      "v104xv104\n",
      "v104xv106\n",
      "v104xv111\n",
      "v104xv112\n",
      "v104xv113\n",
      "v104xv114\n",
      "v104xv115\n",
      "v104xv120\n",
      "v104xv121\n",
      "v104xv122\n",
      "v104xv125\n",
      "v104xv126\n",
      "v104xv127\n",
      "v104xv129\n",
      "v104xv130\n",
      "v104xv131\n",
      "v106xv106\n",
      "v106xv111\n",
      "v106xv112\n",
      "v106xv113\n",
      "v106xv114\n",
      "v106xv115\n",
      "v106xv120\n",
      "v106xv121\n",
      "v106xv122\n",
      "v106xv125\n",
      "v106xv126\n",
      "v106xv127\n",
      "v106xv129\n",
      "v106xv130\n",
      "v106xv131\n",
      "v111xv111\n",
      "v111xv112\n",
      "v111xv113\n",
      "v111xv114\n",
      "v111xv115\n",
      "v111xv120\n",
      "v111xv121\n",
      "v111xv122\n",
      "v111xv125\n",
      "v111xv126\n",
      "v111xv127\n",
      "v111xv129\n",
      "v111xv130\n",
      "v111xv131\n",
      "v112xv112\n",
      "v112xv113\n",
      "v112xv114\n",
      "v112xv115\n",
      "v112xv120\n",
      "v112xv121\n",
      "v112xv122\n",
      "v112xv125\n",
      "v112xv126\n",
      "v112xv127\n",
      "v112xv129\n",
      "v112xv130\n",
      "v112xv131\n",
      "v113xv113\n",
      "v113xv114\n",
      "v113xv115\n",
      "v113xv120\n",
      "v113xv121\n",
      "v113xv122\n",
      "v113xv125\n",
      "v113xv126\n",
      "v113xv127\n",
      "v113xv129\n",
      "v113xv130\n",
      "v113xv131\n",
      "v114xv114\n",
      "v114xv115\n",
      "v114xv120\n",
      "v114xv121\n",
      "v114xv122\n",
      "v114xv125\n",
      "v114xv126\n",
      "v114xv127\n",
      "v114xv129\n",
      "v114xv130\n",
      "v114xv131\n",
      "v115xv115\n",
      "v115xv120\n",
      "v115xv121\n",
      "v115xv122\n",
      "v115xv125\n",
      "v115xv126\n",
      "v115xv127\n",
      "v115xv129\n",
      "v115xv130\n",
      "v115xv131\n",
      "v120xv120\n",
      "v120xv121\n",
      "v120xv122\n",
      "v120xv125\n",
      "v120xv126\n",
      "v120xv127\n",
      "v120xv129\n",
      "v120xv130\n",
      "v120xv131\n",
      "v121xv121\n",
      "v121xv122\n",
      "v121xv125\n",
      "v121xv126\n",
      "v121xv127\n",
      "v121xv129\n",
      "v121xv130\n",
      "v121xv131\n",
      "v122xv122\n",
      "v122xv125\n",
      "v122xv126\n",
      "v122xv127\n",
      "v122xv129\n",
      "v122xv130\n",
      "v122xv131\n",
      "v125xv125\n",
      "v125xv126\n",
      "v125xv127\n",
      "v125xv129\n",
      "v125xv130\n",
      "v125xv131\n",
      "v126xv126\n",
      "v126xv127\n",
      "v126xv129\n",
      "v126xv130\n",
      "v126xv131\n",
      "v127xv127\n",
      "v127xv129\n",
      "v127xv130\n",
      "v127xv131\n",
      "v129xv129\n",
      "v129xv130\n",
      "v129xv131\n",
      "v130xv130\n",
      "v130xv131\n",
      "v131xv131\n"
     ]
    }
   ],
   "source": [
    "start=80\n",
    "mid=start\n",
    "stop=100\n",
    "for i in range(start,stop):\n",
    "    for j in range(mid,stop):\n",
    "        label=colnames[i]+\"x\"+colnames[j]\n",
    "        print(label)\n",
    "        train[label]=train.iloc[:,i]*train.iloc[:,j]\n",
    "    mid=mid+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114321, 1252)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n",
      "Clearing...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import ensemble\n",
    "\n",
    "\n",
    "print('Load data...')\n",
    "train = pd.read_csv(\"C://users//Robert//Downloads//train.csv\")\n",
    "target = train['target'].values\n",
    "train = train.drop(['ID','target','v8','v23','v25','v31','v36','v37','v46','v51','v53','v54','v63','v73','v75','v79','v81','v82','v89','v92','v95','v105','v107','v108','v109','v110','v116','v117','v118','v119','v123','v124','v128'],axis=1)\n",
    "test = pd.read_csv(\"C://users//Robert//Downloads//test.csv\")\n",
    "id_test = test['ID'].values\n",
    "test = test.drop(['ID','v8','v23','v25','v31','v36','v37','v46','v51','v53','v54','v63','v73','v75','v79','v81','v82','v89','v92','v95','v105','v107','v108','v109','v110','v116','v117','v118','v119','v123','v124','v128'],axis=1)\n",
    "train['pop']=train.shape[1]-train.count(axis=1, level=None, numeric_only=False)\n",
    "test['pop']=test.shape[1]-test.count(axis=1, level=None, numeric_only=False)\n",
    "colnames=list(train.columns.values)\n",
    "for value in colnames:\n",
    "    newcol=value+\"p\"\n",
    "    train[newcol]=train[value].isnull().astype(int)\n",
    "    test[newcol]=test[value].isnull().astype(int)\n",
    "print('Clearing...')\n",
    "for (train_name, train_series), (test_name, test_series) in zip(train.iteritems(),test.iteritems()):\n",
    "    if train_series.dtype == 'O':\n",
    "        #for objects: factorize\n",
    "        train[train_name], tmp_indexer = pd.factorize(train[train_name])\n",
    "        test[test_name] = tmp_indexer.get_indexer(test[test_name])\n",
    "        #but now we have -1 values (NaN)\n",
    "    else:\n",
    "        #for int or float: fill NaN\n",
    "        tmp_len = len(train[train_series.isnull()])\n",
    "        if tmp_len>0:\n",
    "            #print \"mean\", train_series.mean()\n",
    "            train.loc[train_series.isnull(), train_name] = -999 \n",
    "        #and Test\n",
    "        tmp_len = len(test[test_series.isnull()])\n",
    "        if tmp_len>0:\n",
    "            test.loc[test_series.isnull(), test_name] = -999\n",
    "colnames=list(train.columns.values)\n",
    "colnames=colnames[0:100]\n",
    "len(colnames)\n",
    "a=0\n",
    "n=0\n",
    "l=len(colnames)\n",
    "for i in range(n,l):\n",
    "    print(i)\n",
    "    for j in range(a,l):\n",
    "        label=colnames[i]+\"x\"+colnames[j]\n",
    "        train[label]=train.iloc[:,i]*train.iloc[:,j]\n",
    "    a=a+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n",
      "Clearing...\n"
     ]
    }
   ],
   "source": [
    "colnames=list(train.columns.values)\n",
    "colnames=colnames[0:100]\n",
    "len(colnames)\n",
    "for i in colnames:\n",
    "    l=len(colnames)\n",
    "    for j in range(0,l):\n",
    "        label=i+\"x\"+colnames[0+j]\n",
    "        train[label]=train[i]*train[colnames[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colnames=list(train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             19.804975\n",
       "1          -8295.663015\n",
       "2             22.760179\n",
       "3             15.190475\n",
       "4         998001.000000\n",
       "5          -8961.132875\n",
       "6             10.391316\n",
       "7         998001.000000\n",
       "8             18.085169\n",
       "9              9.632796\n",
       "10        998001.000000\n",
       "11        998001.000000\n",
       "12        998001.000000\n",
       "13            22.469957\n",
       "14            20.518745\n",
       "15        998001.000000\n",
       "16            11.862072\n",
       "17        998001.000000\n",
       "18        998001.000000\n",
       "19        998001.000000\n",
       "20            18.456687\n",
       "21             8.544889\n",
       "22            12.636956\n",
       "23             4.235636\n",
       "24            12.013922\n",
       "25        998001.000000\n",
       "26        998001.000000\n",
       "27            24.033332\n",
       "28            14.945568\n",
       "29            22.588064\n",
       "              ...      \n",
       "114291    998001.000000\n",
       "114292        13.465409\n",
       "114293        32.981945\n",
       "114294    998001.000000\n",
       "114295        15.780258\n",
       "114296    998001.000000\n",
       "114297        19.622315\n",
       "114298        23.852601\n",
       "114299         9.851724\n",
       "114300        18.228995\n",
       "114301    998001.000000\n",
       "114302        17.350774\n",
       "114303    998001.000000\n",
       "114304    998001.000000\n",
       "114305        24.570292\n",
       "114306        23.771766\n",
       "114307    998001.000000\n",
       "114308    998001.000000\n",
       "114309    998001.000000\n",
       "114310    998001.000000\n",
       "114311    998001.000000\n",
       "114312        14.117458\n",
       "114313        21.873071\n",
       "114314         3.589359\n",
       "114315    998001.000000\n",
       "114316    998001.000000\n",
       "114317    998001.000000\n",
       "114318    -11927.076152\n",
       "114319     -6696.018959\n",
       "114320        18.401834\n",
       "Name: v76xv98, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['v76xv98']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
